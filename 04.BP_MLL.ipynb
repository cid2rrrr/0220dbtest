{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Load Datasets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import tensorflow as tf"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "+ X_label IMG"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "def load(file_path):\n",
    "    img = tf.io.read_file(file_path)\n",
    "    img = tf.image.decode_png(img, channels=3)\n",
    "    img = tf.image.convert_image_dtype(img, tf.float32)\n",
    "    img = tf.image.resize(img, size=(150, 150))\n",
    "    return img"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "d_path = 'D:\\AlbumCover/'\n",
    "img_dataset = pd.read_csv('./dataset/img.csv')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "img_arr = None\n",
    "\n",
    "for path in img_dataset['path']:\n",
    "    if img_arr is None:\n",
    "        img_arr = np.expand_dims(load(d_path + path), axis=0)\n",
    "    else:\n",
    "        img_arr = np.append(img_arr, np.expand_dims(load(d_path + path), axis=0), axis=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# check np array is well defined\n",
    "img_arr.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "+ X_label Facial"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pre_facial = pd.read_csv('./dataset/facial.csv')\n",
    "\n",
    "if 'Unnamed: 0' in pre_facial.columns:\n",
    "    pre_facial = pre_facial.drop('Unnamed: 0', axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "imsi = pre_facial.copy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# categorical data to one-hot\n",
    "fac_input_df = pd.get_dummies(imsi, prefix=['gender', 'dominant_race'])\n",
    "\n",
    "# Normalization\n",
    "fac_input_norm = (fac_input_df - fac_input_df.mean()) / fac_input_df.std()\n",
    "\n",
    "fac_input = np.array(fac_input_norm)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# check np array is well defined\n",
    "fac_input.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "+ X_label Color"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "clr_data = pd.read_csv('./dataset/clr.csv')\n",
    "if 'Unnamed: 0' in pre_facial.columns:\n",
    "    clr_data = clr_data.drop('Unnamed: 0', axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "clr_input = np.array( (clr_data - clr_data.mean())/clr_data.std() )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# check np array is well defined\n",
    "clr_input.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "+ y_label"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_data = pd.read_csv('./dataset/y_label.csv')\n",
    "\n",
    "y_out = np.array(y_data)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Modeling w/ BP-MLL"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Make Model using keras functional api"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.layers import Input\n",
    "from keras.models import Model\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras.applications.resnet50 import ResNet50\n",
    "\n",
    "def multi_input_model(input_shape, classes):\n",
    "    # IMG Conv Model (not in use)\n",
    "    # real_conv_input = tf.keras.Input(shape=(150,150,3,))\n",
    "    # conv_input = tf.keras.layers.experimental.preprocessing.Rescaling(1./255, input_shape=(input_shape, input_shape))\n",
    "    # conv_layer = tf.keras.layers.Conv2D(filters=16, kernel_size=(5, 5), activation=\"relu\")(real_conv_input)\n",
    "    # conv_laye2 = keras.layers.Dropout(0.2)(conv_layer)\n",
    "    # conv_laye3 = keras.layers.Conv2D(filters=64, kernel_size=(5, 5), activation='relu')(conv_laye2)\n",
    "    # conv_laye4 = keras.layers.MaxPooling2D(pool_size=(4,4))(conv_laye3)\n",
    "    # conv_laye5 = keras.layers.Dropout(0.2)(conv_laye4)\n",
    "    # conv_laye6 = keras.layers.Conv2D(filters=64, kernel_size=(5, 5), activation='relu')(conv_laye5)\n",
    "    # conv_laye7 = keras.layers.MaxPooling2D(pool_size=(2,2))(conv_laye6)\n",
    "    # conv_laye8 = keras.layers.Dropout(0.2)(conv_laye7)\n",
    "    # conv_laye9 = keras.layers.Flatten()(conv_laye8)\n",
    "    # conv_lay10 = keras.layers.Dense(64, activation='relu')(conv_laye9)\n",
    "    # conv_output = keras.layers.Dense(classes, activation='softmax')(conv_lay10)\n",
    "    \n",
    "    # IMG ResNet Model\n",
    "    # resnet_input = tf.keras.layers.experimental.preprocessing.Rescaling(1./255, input_shape=(input_shape, input_shape))\n",
    "    resnet_input = tf.keras.Input(shape=(input_shape,input_shape,3))\n",
    "    #resnet_resc = tf.keras.preprocessing.Rescaling(1.0/255)(resnet_input)\n",
    "    resnet_output = tf.keras.applications.ResNet50(weights=None, input_shape=(input_shape,input_shape,3), classes=classes)(resnet_input)\n",
    "    \n",
    "    # face MLP Model\n",
    "    real_face_input = tf.keras.layers.Input(shape=(16,))\n",
    "    face_input = tf.keras.layers.Dense(256, activation='selu', kernel_initializer='lecun_normal')(real_face_input)\n",
    "    # face_layer = keras.layers.Dropout(0.2)(face_input)\n",
    "    face_laye2 = tf.keras.layers.Dense(128, activation='selu', kernel_initializer='lecun_normal')(face_input)#(face_layer)\n",
    "    # face_laye3 = keras.layers.Dropout(0.2)(face_laye2)\n",
    "    face_laye4 = tf.keras.layers.Dense(64, activation='selu', kernel_initializer='lecun_normal')(face_laye2)#(face_laye3)\n",
    "    # face_laye5 = keras.layers.Dropout(0.2)(face_laye4)\n",
    "    face_output = tf.keras.layers.Dense(classes, activation='relu')(face_laye4)#(face_laye5)\n",
    "    \n",
    "    # # face MLP Model /w relu\n",
    "    # real_face_input = tf.keras.layers.Input(shape=(16,))\n",
    "    # face_input = tf.keras.layers.Dense(256, activation='relu')(real_face_input)\n",
    "    # #face_layer = keras.layers.Dropout(0.2)(face_input)\n",
    "    # face_laye2 = tf.keras.layers.Dense(128, activation='relu')(face_input)#(face_layer)\n",
    "    # #face_laye3 = keras.layers.Dropout(0.2)(face_laye2)\n",
    "    # face_laye4 = tf.keras.layers.Dense(64, activation='relu')(face_laye2)#(face_laye3)\n",
    "    # #face_laye5 = keras.layers.Dropout(0.2)(face_laye4)\n",
    "    # face_output = tf.keras.layers.Dense(classes, activation='softmax')(face_laye4)#(face_laye5)\n",
    "    \n",
    "    \n",
    "    \n",
    "    # clr MLP Model\n",
    "    real_clr_input = tf.keras.layers.Input(shape=(3,))\n",
    "    clr_input = tf.keras.layers.Dense(64, activation='relu')(real_clr_input)\n",
    "    clr_layer = tf.keras.layers.Dense(32, activation='relu')(clr_input)\n",
    "    clr_output = tf.keras.layers.Dense(classes, activation='relu')(clr_layer)\n",
    "    \n",
    "    \n",
    "    # concatenate\n",
    "    concat = tf.keras.layers.Concatenate(axis=-1)([resnet_output ,face_output, clr_output])\n",
    "    \n",
    "    # final model\n",
    "    final_input = tf.keras.layers.Dense(128, activation='relu')(concat)\n",
    "    final_layer = tf.keras.layers.Dropout(0.2)(final_input)\n",
    "    final_laye2 = tf.keras.layers.Dense(64, activation='relu')(final_layer)\n",
    "    final_output = tf.keras.layers.Dense(classes, activation='sigmoid')(final_laye2)\n",
    "    \n",
    "    \n",
    "    model = tf.keras.models.Model([resnet_input, real_face_input, real_clr_input], final_output)\n",
    "    \n",
    "    return model\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "NUM_CLASSES = 13\n",
    "IMG_SIZE = 150"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = multi_input_model(IMG_SIZE, NUM_CLASSES)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# you can see model summary\n",
    "\n",
    "tf.keras.utils.plot_model(model, show_shapes=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Compiling the Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "from sklearn.metrics import log_loss # not in use right now\n",
    "\n",
    "# 성능 기반 스케줄링\n",
    "lr_scheduler = tf.keras.callbacks.ReduceLROnPlateau(factor=0.5, patience=5)\n",
    "\n",
    "optimizer = tf.keras.optimizers.SGD(learning_rate=0.02, momentum=0.9)\n",
    "\n",
    "model.compile(loss = tf.nn.softmax_cross_entropy_with_logits,\n",
    "              optimizer= optimizer,\n",
    "              metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "with tf.device(\"/device:GPU:0\"):\n",
    "  history = model.fit(\n",
    "  x=[img_arr,fac_input, clr_input],\n",
    "  y=y_out,\n",
    "  validation_split=0.2,\n",
    "  epochs=30,\n",
    "  callbacks=[lr_scheduler],\n",
    "  batch_size=32\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "\n",
    "acc = history.history['accuracy']\n",
    "val_acc = history.history['val_accuracy']\n",
    "\n",
    "loss = history.history['loss']\n",
    "val_loss = history.history['val_loss']\n",
    "\n",
    "epochs_range = range(30)\n",
    "\n",
    "plt.figure(figsize=(8, 8))\n",
    "plt.subplot(1, 2, 1)\n",
    "plt.plot(epochs_range, acc, label='Training Accuracy')\n",
    "plt.plot(epochs_range, val_acc, label='Validation Accuracy')\n",
    "plt.legend(loc='lower right')\n",
    "plt.title('Training and Validation Accuracy')\n",
    "\n",
    "plt.subplot(1, 2, 2)\n",
    "plt.plot(epochs_range, loss, label='Training Loss')\n",
    "plt.plot(epochs_range, val_loss, label='Validation Loss')\n",
    "plt.legend(loc='upper right')\n",
    "plt.title('Training and Validation Loss')\n",
    "plt.show()"
   ]
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "9cda7dce2d78f3c21f6a73de63970ac35274352b7a0f13225446d99cae259cfd"
  },
  "kernelspec": {
   "display_name": "Python 3.9.7 ('base')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
