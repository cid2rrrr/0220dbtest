{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "\n",
    "def logloss(true_label, predicted, eps=1e-15):\n",
    "    p = np.clip(predicted, eps, 1-eps)\n",
    "    if true_label == 1:\n",
    "        return -np.log(p)\n",
    "    else:\n",
    "        return -np.log(1-p)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([3.45395760e+01, 9.99200722e-16])"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "logloss([1,1],[1,0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "def my_logloss(answer_array, proba_array):\n",
    "    \n",
    "    # 0이면 무한대 값이 나오기 때문에 0에 가까운 값으로 치환해줍니다.\n",
    "    MIN_VALUE = 1e-15\n",
    "\n",
    "    # array의 크기를 가져옵니다.\n",
    "    size = answer_array.shape[0]\n",
    "\n",
    "    # 반복문을 사용해서 logloss의 합을 계산합니다.\n",
    "    logloss_sum = 0\n",
    "    # zip함수로 묶으면 함께 순회할 수 있습니다.\n",
    "    for answer, arr in zip(answer_array, proba_array):\n",
    "        proba = arr[answer - 1]\n",
    "\n",
    "        # 0이면 무한대 값이 나오기 때문에 0에 가까운 값으로 치환해줍니다.\n",
    "        if proba <= MIN_VALUE:\n",
    "            proba = MIN_VALUE\n",
    "\n",
    "        # 음의 로그함수에 넣어서 logloss 계산\n",
    "        logloss_sum += -np.log(proba)\n",
    "\n",
    "    # logloss의 평균 계산\n",
    "    result = logloss_sum / size\n",
    "\n",
    "    # 반환\n",
    "    return result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "17.269388197455342"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "my_logloss(np.array([1,1]),np.array([[1,0],[0,0]]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "from tensorflow.keras import Sequential\n",
    "from tensorflow.keras.layers import Dense\n",
    "\n",
    "\n",
    "def my_model():\n",
    "    model = Sequential()\n",
    "    model.add(tf.keras.layers.Flatten(input_shape=(28,28)))\n",
    "    model.add(Dense(units=100, activation='relu'))\n",
    "    model.add(Dense(units=50, activation='relu'))\n",
    "    model.add(Dense(units=10, activation='relu'))\n",
    "    model.add(Dense(units=4, activation='relu'))\n",
    "    model.add(Dense(10, activation='softmax'))\n",
    "    return model\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = my_model()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "# create a random vector of shape (100,2)\n",
    "x = np.random.sample((100,2))\n",
    "# make a dataset from a numpy array\n",
    "dataset = tf.data.Dataset.from_tensor_slices(x)\n",
    "##\n",
    "features, labels = (np.random.sample((100,2)), np.random.sample((100,1)))\n",
    "dataset = tf.data.Dataset.from_tensor_slices((features,labels))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [],
   "source": [
    "from bpmll import bp_mll_loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.compile(optimizer='adam', loss = bp_mll_loss, metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [],
   "source": [
    "mnist = tf.keras.datasets.mnist\n",
    "\n",
    "(x_train, y_train), (x_test, yy_test) = mnist.load_data()\n",
    "x_train, x_test = x_train / 255.0, x_test / 255.0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [
    {
     "ename": "TypeError",
     "evalue": "in user code:\n\n    File \"c:\\Users\\cid2r\\anaconda3\\lib\\site-packages\\keras\\engine\\training.py\", line 1021, in train_function  *\n        return step_function(self, iterator)\n    File \"c:\\Users\\cid2r\\anaconda3\\lib\\site-packages\\bpmll\\bpmll.py\", line 20, in bp_mll_loss  *\n        y_i = tf.equal(y_true, tf.ones(shape))\n\n    TypeError: Input 'y' of 'Equal' Op has type float32 that does not match type uint8 of argument 'x'.\n",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m~\\AppData\\Local\\Temp/ipykernel_14964/596097040.py\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[1;32m----> 1\u001b[1;33m \u001b[0mmodel\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mx_train\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0myyy\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;32mc:\\Users\\cid2r\\anaconda3\\lib\\site-packages\\keras\\utils\\traceback_utils.py\u001b[0m in \u001b[0;36merror_handler\u001b[1;34m(*args, **kwargs)\u001b[0m\n\u001b[0;32m     65\u001b[0m     \u001b[1;32mexcept\u001b[0m \u001b[0mException\u001b[0m \u001b[1;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[1;33m:\u001b[0m  \u001b[1;31m# pylint: disable=broad-except\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     66\u001b[0m       \u001b[0mfiltered_tb\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0m_process_traceback_frames\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0me\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m__traceback__\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 67\u001b[1;33m       \u001b[1;32mraise\u001b[0m \u001b[0me\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mwith_traceback\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mfiltered_tb\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;32mfrom\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     68\u001b[0m     \u001b[1;32mfinally\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     69\u001b[0m       \u001b[1;32mdel\u001b[0m \u001b[0mfiltered_tb\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\Users\\cid2r\\anaconda3\\lib\\site-packages\\tensorflow\\python\\framework\\func_graph.py\u001b[0m in \u001b[0;36mautograph_handler\u001b[1;34m(*args, **kwargs)\u001b[0m\n\u001b[0;32m   1145\u001b[0m           \u001b[1;32mexcept\u001b[0m \u001b[0mException\u001b[0m \u001b[1;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[1;33m:\u001b[0m  \u001b[1;31m# pylint:disable=broad-except\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1146\u001b[0m             \u001b[1;32mif\u001b[0m \u001b[0mhasattr\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0me\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;34m\"ag_error_metadata\"\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1147\u001b[1;33m               \u001b[1;32mraise\u001b[0m \u001b[0me\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mag_error_metadata\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mto_exception\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0me\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   1148\u001b[0m             \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1149\u001b[0m               \u001b[1;32mraise\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mTypeError\u001b[0m: in user code:\n\n    File \"c:\\Users\\cid2r\\anaconda3\\lib\\site-packages\\keras\\engine\\training.py\", line 1021, in train_function  *\n        return step_function(self, iterator)\n    File \"c:\\Users\\cid2r\\anaconda3\\lib\\site-packages\\bpmll\\bpmll.py\", line 20, in bp_mll_loss  *\n        y_i = tf.equal(y_true, tf.ones(shape))\n\n    TypeError: Input 'y' of 'Equal' Op has type float32 that does not match type uint8 of argument 'x'.\n"
     ]
    }
   ],
   "source": [
    "model.fit(x_train,yyy)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "yy_train = pd.get_dummies(y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [],
   "source": [
    "yyy = np.array(yy_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [],
   "source": [
    "yeast = np.load('yeast.npz')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_train = yeast['X_train']\n",
    "y_train = yeast['Y_train']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [],
   "source": [
    "n = x_train.shape[0]\n",
    "dim_no = x_train.shape[1]\n",
    "class_no = y_train.shape[1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = Sequential()\n",
    "model.add(Dense(128, input_dim=dim_no, activation='relu', kernel_initializer='glorot_uniform'))\n",
    "model.add(Dense(64, activation='relu', kernel_initializer='glorot_uniform'))\n",
    "model.add(Dense(class_no, activation='sigmoid', kernel_initializer='glorot_uniform'))\n",
    "model.compile(loss=bp_mll_loss, optimizer='adagrad', metrics=[])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/100\n",
      "47/47 [==============================] - 1s 6ms/step - loss: 1.0030\n",
      "Epoch 2/100\n",
      "47/47 [==============================] - 0s 6ms/step - loss: 1.0015\n",
      "Epoch 3/100\n",
      "47/47 [==============================] - 0s 5ms/step - loss: 1.0001\n",
      "Epoch 4/100\n",
      "47/47 [==============================] - 0s 4ms/step - loss: 0.9988\n",
      "Epoch 5/100\n",
      "47/47 [==============================] - 0s 4ms/step - loss: 0.9976\n",
      "Epoch 6/100\n",
      "47/47 [==============================] - 0s 4ms/step - loss: 0.9964\n",
      "Epoch 7/100\n",
      "47/47 [==============================] - 0s 4ms/step - loss: 0.9953\n",
      "Epoch 8/100\n",
      "47/47 [==============================] - 0s 4ms/step - loss: 0.9942\n",
      "Epoch 9/100\n",
      "47/47 [==============================] - 0s 4ms/step - loss: 0.9931\n",
      "Epoch 10/100\n",
      "47/47 [==============================] - 0s 3ms/step - loss: 0.9921\n",
      "Epoch 11/100\n",
      "47/47 [==============================] - 0s 4ms/step - loss: 0.9911\n",
      "Epoch 12/100\n",
      "47/47 [==============================] - 0s 3ms/step - loss: 0.9902\n",
      "Epoch 13/100\n",
      "47/47 [==============================] - 0s 3ms/step - loss: 0.9893\n",
      "Epoch 14/100\n",
      "47/47 [==============================] - 0s 3ms/step - loss: 0.9883\n",
      "Epoch 15/100\n",
      "47/47 [==============================] - 0s 4ms/step - loss: 0.9874\n",
      "Epoch 16/100\n",
      "47/47 [==============================] - 0s 4ms/step - loss: 0.9865\n",
      "Epoch 17/100\n",
      "47/47 [==============================] - 0s 4ms/step - loss: 0.9857\n",
      "Epoch 18/100\n",
      "47/47 [==============================] - 0s 4ms/step - loss: 0.9848\n",
      "Epoch 19/100\n",
      "47/47 [==============================] - 0s 5ms/step - loss: 0.9840\n",
      "Epoch 20/100\n",
      "47/47 [==============================] - 0s 4ms/step - loss: 0.9831\n",
      "Epoch 21/100\n",
      "47/47 [==============================] - 0s 5ms/step - loss: 0.9823\n",
      "Epoch 22/100\n",
      "47/47 [==============================] - 0s 5ms/step - loss: 0.9815\n",
      "Epoch 23/100\n",
      "47/47 [==============================] - 0s 5ms/step - loss: 0.9807\n",
      "Epoch 24/100\n",
      "47/47 [==============================] - 0s 5ms/step - loss: 0.9799\n",
      "Epoch 25/100\n",
      "47/47 [==============================] - 0s 5ms/step - loss: 0.9791\n",
      "Epoch 26/100\n",
      "47/47 [==============================] - 0s 5ms/step - loss: 0.9783\n",
      "Epoch 27/100\n",
      "47/47 [==============================] - 0s 5ms/step - loss: 0.9775\n",
      "Epoch 28/100\n",
      "47/47 [==============================] - 0s 5ms/step - loss: 0.9767\n",
      "Epoch 29/100\n",
      "47/47 [==============================] - 0s 5ms/step - loss: 0.9760\n",
      "Epoch 30/100\n",
      "47/47 [==============================] - 0s 4ms/step - loss: 0.9752\n",
      "Epoch 31/100\n",
      "47/47 [==============================] - 0s 4ms/step - loss: 0.9744\n",
      "Epoch 32/100\n",
      "47/47 [==============================] - 0s 4ms/step - loss: 0.9736\n",
      "Epoch 33/100\n",
      "47/47 [==============================] - 0s 4ms/step - loss: 0.9729\n",
      "Epoch 34/100\n",
      "47/47 [==============================] - 0s 4ms/step - loss: 0.9721\n",
      "Epoch 35/100\n",
      "47/47 [==============================] - 0s 4ms/step - loss: 0.9714\n",
      "Epoch 36/100\n",
      "47/47 [==============================] - 0s 4ms/step - loss: 0.9706\n",
      "Epoch 37/100\n",
      "47/47 [==============================] - 0s 5ms/step - loss: 0.9698\n",
      "Epoch 38/100\n",
      "47/47 [==============================] - 0s 4ms/step - loss: 0.9691\n",
      "Epoch 39/100\n",
      "47/47 [==============================] - 0s 4ms/step - loss: 0.9683\n",
      "Epoch 40/100\n",
      "47/47 [==============================] - 0s 4ms/step - loss: 0.9676\n",
      "Epoch 41/100\n",
      "47/47 [==============================] - 0s 4ms/step - loss: 0.9668\n",
      "Epoch 42/100\n",
      "47/47 [==============================] - 0s 4ms/step - loss: 0.9661\n",
      "Epoch 43/100\n",
      "47/47 [==============================] - 0s 4ms/step - loss: 0.9653\n",
      "Epoch 44/100\n",
      "47/47 [==============================] - 0s 4ms/step - loss: 0.9646\n",
      "Epoch 45/100\n",
      "47/47 [==============================] - 0s 4ms/step - loss: 0.9638\n",
      "Epoch 46/100\n",
      "47/47 [==============================] - 0s 4ms/step - loss: 0.9630\n",
      "Epoch 47/100\n",
      "47/47 [==============================] - 0s 4ms/step - loss: 0.9623\n",
      "Epoch 48/100\n",
      "47/47 [==============================] - 0s 4ms/step - loss: 0.9615\n",
      "Epoch 49/100\n",
      "47/47 [==============================] - 0s 4ms/step - loss: 0.9607\n",
      "Epoch 50/100\n",
      "47/47 [==============================] - 0s 4ms/step - loss: 0.9600\n",
      "Epoch 51/100\n",
      "47/47 [==============================] - 0s 4ms/step - loss: 0.9592\n",
      "Epoch 52/100\n",
      "47/47 [==============================] - 0s 4ms/step - loss: 0.9584\n",
      "Epoch 53/100\n",
      "47/47 [==============================] - 0s 5ms/step - loss: 0.9576\n",
      "Epoch 54/100\n",
      "47/47 [==============================] - 0s 5ms/step - loss: 0.9569\n",
      "Epoch 55/100\n",
      "47/47 [==============================] - 0s 4ms/step - loss: 0.9561\n",
      "Epoch 56/100\n",
      "47/47 [==============================] - 0s 5ms/step - loss: 0.9553\n",
      "Epoch 57/100\n",
      "47/47 [==============================] - 0s 4ms/step - loss: 0.9545\n",
      "Epoch 58/100\n",
      "47/47 [==============================] - 0s 4ms/step - loss: 0.9537\n",
      "Epoch 59/100\n",
      "47/47 [==============================] - 0s 4ms/step - loss: 0.9529\n",
      "Epoch 60/100\n",
      "47/47 [==============================] - 0s 4ms/step - loss: 0.9521\n",
      "Epoch 61/100\n",
      "47/47 [==============================] - 0s 4ms/step - loss: 0.9513\n",
      "Epoch 62/100\n",
      "47/47 [==============================] - 0s 4ms/step - loss: 0.9505\n",
      "Epoch 63/100\n",
      "47/47 [==============================] - 0s 4ms/step - loss: 0.9497\n",
      "Epoch 64/100\n",
      "47/47 [==============================] - 0s 4ms/step - loss: 0.9489\n",
      "Epoch 65/100\n",
      "47/47 [==============================] - 0s 4ms/step - loss: 0.9481\n",
      "Epoch 66/100\n",
      "47/47 [==============================] - 0s 5ms/step - loss: 0.9472\n",
      "Epoch 67/100\n",
      "47/47 [==============================] - 0s 5ms/step - loss: 0.9464\n",
      "Epoch 68/100\n",
      "47/47 [==============================] - 0s 5ms/step - loss: 0.9456\n",
      "Epoch 69/100\n",
      "47/47 [==============================] - 0s 4ms/step - loss: 0.9448\n",
      "Epoch 70/100\n",
      "47/47 [==============================] - 0s 4ms/step - loss: 0.9439\n",
      "Epoch 71/100\n",
      "47/47 [==============================] - 0s 4ms/step - loss: 0.9431\n",
      "Epoch 72/100\n",
      "47/47 [==============================] - 0s 4ms/step - loss: 0.9422\n",
      "Epoch 73/100\n",
      "47/47 [==============================] - 0s 4ms/step - loss: 0.9414\n",
      "Epoch 74/100\n",
      "47/47 [==============================] - 0s 4ms/step - loss: 0.9405\n",
      "Epoch 75/100\n",
      "47/47 [==============================] - 0s 4ms/step - loss: 0.9397\n",
      "Epoch 76/100\n",
      "47/47 [==============================] - 0s 4ms/step - loss: 0.9388\n",
      "Epoch 77/100\n",
      "47/47 [==============================] - 0s 4ms/step - loss: 0.9379\n",
      "Epoch 78/100\n",
      "47/47 [==============================] - 0s 5ms/step - loss: 0.9371\n",
      "Epoch 79/100\n",
      "47/47 [==============================] - 0s 5ms/step - loss: 0.9362\n",
      "Epoch 80/100\n",
      "47/47 [==============================] - 0s 5ms/step - loss: 0.9353\n",
      "Epoch 81/100\n",
      "47/47 [==============================] - 0s 5ms/step - loss: 0.9344\n",
      "Epoch 82/100\n",
      "47/47 [==============================] - 0s 5ms/step - loss: 0.9336\n",
      "Epoch 83/100\n",
      "47/47 [==============================] - 0s 4ms/step - loss: 0.9327\n",
      "Epoch 84/100\n",
      "47/47 [==============================] - 0s 4ms/step - loss: 0.9318\n",
      "Epoch 85/100\n",
      "47/47 [==============================] - 0s 4ms/step - loss: 0.9309\n",
      "Epoch 86/100\n",
      "47/47 [==============================] - 0s 4ms/step - loss: 0.9300\n",
      "Epoch 87/100\n",
      "47/47 [==============================] - 0s 4ms/step - loss: 0.9291\n",
      "Epoch 88/100\n",
      "47/47 [==============================] - 0s 4ms/step - loss: 0.9282\n",
      "Epoch 89/100\n",
      "47/47 [==============================] - 0s 4ms/step - loss: 0.9273\n",
      "Epoch 90/100\n",
      "47/47 [==============================] - 0s 4ms/step - loss: 0.9263\n",
      "Epoch 91/100\n",
      "47/47 [==============================] - 0s 4ms/step - loss: 0.9254\n",
      "Epoch 92/100\n",
      "47/47 [==============================] - 0s 4ms/step - loss: 0.9245\n",
      "Epoch 93/100\n",
      "47/47 [==============================] - 0s 5ms/step - loss: 0.9236\n",
      "Epoch 94/100\n",
      "47/47 [==============================] - 0s 5ms/step - loss: 0.9227\n",
      "Epoch 95/100\n",
      "47/47 [==============================] - 0s 5ms/step - loss: 0.9217\n",
      "Epoch 96/100\n",
      "47/47 [==============================] - 0s 4ms/step - loss: 0.9208\n",
      "Epoch 97/100\n",
      "47/47 [==============================] - 0s 5ms/step - loss: 0.9199\n",
      "Epoch 98/100\n",
      "47/47 [==============================] - 0s 4ms/step - loss: 0.9189\n",
      "Epoch 99/100\n",
      "47/47 [==============================] - 0s 4ms/step - loss: 0.9180\n",
      "Epoch 100/100\n",
      "47/47 [==============================] - 0s 4ms/step - loss: 0.9170\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x1c67ceecdf0>"
      ]
     },
     "execution_count": 80,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.fit(x_train, yy_train, epochs=100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "dtype('float64')"
      ]
     },
     "execution_count": 72,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x_train.dtype"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "dtype('int64')"
      ]
     },
     "execution_count": 73,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_train.dtype"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {},
   "outputs": [],
   "source": [
    "yy_train = y_train.astype('float64')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0., 0., 1., ..., 0., 0., 0.],\n",
       "       [0., 0., 0., ..., 1., 1., 0.],\n",
       "       [0., 1., 1., ..., 1., 1., 0.],\n",
       "       ...,\n",
       "       [0., 0., 0., ..., 1., 1., 0.],\n",
       "       [0., 0., 0., ..., 1., 1., 0.],\n",
       "       [0., 1., 1., ..., 1., 1., 0.]])"
      ]
     },
     "execution_count": 77,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "yy_train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "9cda7dce2d78f3c21f6a73de63970ac35274352b7a0f13225446d99cae259cfd"
  },
  "kernelspec": {
   "display_name": "Python 3.9.7 ('base')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
